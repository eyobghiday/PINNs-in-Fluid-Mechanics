@article{IllinoisTech2022-7,
author = {{Illinois Tech}},
keywords = {Ilinois Institute of Technology},
pages = {1-3},
title = {{Lab-07 Controling a quad-copter arm using dSpace Open Loop}},
year = {2023} 
}

@misc{gyroscope.com, url={https://www.gyroscope.com/}, journal={Gyroscope.com - gyroscopes, educational toys and gadgets}, author={Gyroscope Sensors, Brightfusion Ltd}}

@article{statistics, 
title={T-distribution table (one tail and two-tails)}, 
url={https://www.statisticshowto.com/tables/t-distribution-table/}, 
journal={Statistics World}, 
year={2023},
month={Feb}
} 

@misc{mathworks, title={Matlab and Simulink Tools}, url={https://www.mathworks.com/}, journal={MathWorks}} 

@misc{dspace, title={dSpace Control Desk}, url={https://www.dspace.com/en/inc/home.cfm}, journal={dSPACE}}

@article{2017, title={Gyroscope Technology and Applications: A Review in the Industrial Perspective}, volume={17}, ISSN={1424-8220}, url={http://dx.doi.org/10.3390/s17102284}, DOI={10.3390/s17102284}, number={10}, journal={Sensors}, publisher={MDPI AG}, author={Passaro, Vittorio M. N. and Cuccovillo, Antonello and Vaiani, Lorenzo and De Carlo, Martino and Campanella, Carlo Edoardo}, year={2017}, month={Oct}, pages={2284} }

@article{IllinoisTech2022-9,
author = {{Illinois Tech}},
keywords = {Ilinois Institute of Technology},
pages = {1-6},
title = {{Lab-09 Controlling a quad-copter arm using dSpace PID Closed Loop}},
year = {2023} 
}
@article{Arocha2018,
   author = {Marco A Arocha},
   title = {Crank Nicolson Method},
   url={https://matlabgeeks.weebly.com/uploads/8/0/4/8/8048228/crank_nicolson_method_presentation-v5.pdf},
   year = {2018}
}
@article{Eyob2023,
   author = {Ghebreisus Eyob},
   journal = {MMAE-502},
   pages = {1-16},
   title = {Full 2D-difussion equation derivation.pdf},
   url = {https://github.com/eyobghiday/PINNs-in-Fluid-Mechanics/blob/main/Eyob_Ghiday_Difussion_Derivation.pdf},
   year = {2023}
}
@article{Sukumar2022,
abstract = {In this paper, we introduce a new approach based on distance fields to exactly impose boundary conditions in physics-informed deep neural networks. The challenges in satisfying Dirichlet boundary conditions in meshfree and particle methods are well-known. This issue is also pertinent in the development of physics informed neural networks (PINN) for the solution of partial differential equations. We introduce geometry-aware trial functions in artificial neural networks to improve the training in deep learning for partial differential equations. To this end, we use concepts from constructive solid geometry (R-functions) and generalized barycentric coordinates (mean value potential fields) to construct ϕ(x), an approximate distance function to the boundary of a domain in Rd. To exactly impose homogeneous Dirichlet boundary conditions, the trial function is taken as ϕ(x) multiplied by the PINN approximation, and its generalization via transfinite interpolation is used to a priori satisfy inhomogeneous Dirichlet (essential), Neumann (natural), and Robin boundary conditions on complex geometries. In doing so, we eliminate modeling error associated with the satisfaction of boundary conditions in a collocation method and ensure that kinematic admissibility is met pointwise in a Ritz method. With this new ansatz, the training for the neural network is simplified: sole contribution to the loss function is from the residual error at interior collocation points where the governing equation is required to be satisfied. Numerical solutions are computed using strong form collocation and Ritz minimization. To convey the main ideas and to assess the accuracy of the approach, we present numerical solutions for linear and nonlinear boundary-value problems over convex and nonconvex polygonal domains as well as over domains with curved boundaries. Benchmark problems in one dimension for linear elasticity, advection-diffusion, and beam bending; and in two dimensions for the steady-state heat equation, Laplace equation, biharmonic equation (Kirchhoff plate bending), and the nonlinear Eikonal equation are considered. The construction of approximate distance functions using R-functions extends to higher dimensions, and we showcase its use by solving a Poisson problem with homogeneous Dirichlet boundary conditions over the four-dimensional hypercube. The proposed approach consistently outperforms a standard PINN-based collocation method, which underscores the importance of exactly (a priori) satisfying the boundary condition when constructing a loss function in PINN. This study provides a pathway for meshfree analysis to be conducted on the exact geometry without domain discretization.},
author = {Sukumar, N and Srivastava, Ankit},
doi = {https://doi.org/10.1016/j.cma.2021.114333},
issn = {0045-7825},
journal = {Computer Methods in Applied Mechanics and Engineering},
keywords = { Distance function, Exact geometry, Meshfree method, R-function, Transfinite interpolation,Deep learning},
pages = {114333},
title = {{Exact imposition of boundary conditions with distance functions in physics-informed deep neural networks}},
url = {https://www.sciencedirect.com/science/article/pii/S0045782521006186},
volume = {389},
year = {2022}
}

@article{Ursell2005,
author = {Ursell, Tristan},
file = {:Users/eyob/Downloads/dbf-2023/GF/diffusion.pdf:pdf},
journal = {Physics},
mendeley-groups = {Pinn},
title = {{APh Physics Laboratory}},
url = {http://www.physics.nyu.edu/grierlab/methods/node11.html},
year = {2005}
}

@article{Willis1980,
abstract = {Scattering problems in elastodynamics are formulated in terms of integral equations, whose kernels are obtained from the Green's function for a comparison body. The comparison body will usually be taken as homogeneous and elastic in applications but, at least formally, there is no bar to its being inhomogeneous, viscoelastic and non-local. The novel feature of the formulation is the introduction of a "momentum polarization" to cope with density variations in a way that exactly parallels the stress polarization's correspondence with variations in moduli. To illustrate the use of the equations, scattering by an ellipsoidal inhomogeneity in a generally anisotropic matrix is studied in the Rayleigh limit and an asymptotic formula for its scattering cross-section is given. Detailed results are presented for a spheroidal inhomogeneity in an isotropic matrix, with explicit limiting forms for the scattering cross-sections of penny-shaped cracks, rigid circular discs and rigid needles. {\textcopyright} 1980.},
author = {Willis, J. R.},
doi = {10.1016/0022-5096(80)90021-6},
file = {:Users/eyob/Documents/Master/University and College/Armour College of Engineering - Aerospace Engineering/2023 Spring/MMAE-502-01 Engineering Analysis II/Papers/Polarization approach to the scattering of elastic waves - 1.pdf:pdf},
issn = {00225096},
journal = {Journal of the Mechanics and Physics of Solids},
mendeley-groups = {Pinn},
number = {5-6},
pages = {287--305},
title = {{Polarization approach to the scattering of elastic waves-I. Scattering by a single inclusion}},
volume = {28},
year = {1980}
}
@misc{Eyob2023_Git,
author = {Ghebreisus Eyob},
mendeley-groups = {Pinn},
title = {{Application of PiNNs in 2D Difussion Equation}},
url = {https://github.com/eyobghiday/PINNs-in-Fluid-Mechanics},
year = {2023}
}
@article{FernandezdelaMata2023,
abstract = {The last decade has seen a rise in the number and variety of techniques available for data-driven simulation of physical phenomena. One of the most promising approaches is Physics-Informed Neural Networks (PINNs), which can combine both data, obtained from sensors or numerical solvers, and physics knowledge, expressed as partial differential equations. In this work, we investigated the suitability of PINNs to replace current available numerical methods for physics simulations. Although the PINN approach is general and independent of the complexity of the underlying physics equations, a selection of typical heat transfer and fluid dynamics problems was proposed and multiple PINNs were comprehensibly trained and tested to solve them. When PINNs were used as learned simulators, the outcome of our experiments was not entirely satisfactory as not enough accuracy was achieved even though optimal configurations and long training times were used. The main cause for this limitation was found to be the lack of adequate activation functions and specialized architectures, since they proved to have a notable impact on the final accuracy of each model. In turn, PINN architectures showed an accurate behavior when used for parameter inference of partial differential equations from data.},
author = {{Fern{\'{a}}ndez de la Mata}, F{\'{e}}lix and Gij{\'{o}}n, Alfonso and Molina-Solana, Miguel and G{\'{o}}mez-Romero, Juan},
doi = {10.1016/j.physa.2022.128415},
file = {:Users/eyob/Documents/Master/University and College/Armour College of Engineering - Aerospace Engineering/2023 Spring/MMAE-500-01 Data Driven Modeling/1-s2.0-S0378437122009736-main.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Data-driven simulations,Deep learning,Learned simulators,Physics-Informed Neural Networks},
mendeley-groups = {Pinn},
pages = {128415},
publisher = {Elsevier B.V.},
title = {{Physics-informed neural networks for data-driven simulation: Advantages, limitations, and opportunities}},
url = {https://doi.org/10.1016/j.physa.2022.128415},
volume = {610},
year = {2023}
}
@article{Hassan2017,
author = {Hassan, Abdelgabar Adam},
doi = {10.4172/2476-2296.1000152},
file = {:Users/eyob/Downloads/dbf-2023/GF/greens-function-for-the-heat-equation-2476-2296-1000152.pdf:pdf},
journal = {Fluid Mechanics: Open Access},
keywords = {Electrical engineering,Green's function,Heat equation,Quantum mechanics,Sturm-Liouville problem,electrical engineering,green,heat equation,problem,quantum mechanics,s function,sturm-liouville},
mendeley-groups = {Pinn},
number = {02},
pages = {2--7},
title = {{Green's Function for the Heat Equation}},
volume = {04},
year = {2017}
}
@article{Skinner,
abstract = {In this final chapter we will apply the idea of Green's functions to PDEs, enabling us to solve the wave equation, diffusion equation and Laplace equation in unbounded domains. We will also see how to solve the inhomogeneous (i.e. forced) version of these equations, and uncover a relationship, known as Duhamel's principle, between these two classes of problem. In our construction of Green's functions for the heat and wave equation, Fourier transforms play a starring role via the 'differentiation becomes multiplication' rule. We derive Green's identities that enable us to construct Green's functions for Laplace's equation and its inhomogeneous cousin, Poisson's equation. We conclude with a look at the method of images — one of Lord Kelvin's favourite pieces of mathematical trickery. 10.1 Fourier transforms for the heat equation Consider the Cauchy problem for the heat equation ∂$\phi$ ∂t = D∇ 2 $\phi$ (10.1) on R n × [0, ∞), where D is the diffusion constant and where $\phi$ obeys the conditions $\phi$| R n ×{0} = f (x) and lim |x|→∞ $\phi$(x, t) = 0 ∀ t . (10.2) Taking the Fourier transform w.r.t. the spatial variables we have ∂ ∂ $\phi$(k, t) = −D|k| $\phi$(k, t) (10.3) with initial conditio{\~{n}} $\phi$(k, 0) f (k). This equation has a unique solution satisfying the initial conditions, given b $\phi$(k, t) f (k) e −D|k| 2 t . (10.4) Our solution $\phi$(x, t) itself is the inverse Fourier transform of the product o f (k) with the Gaussian e −D|k| 2 t , and the convolution theorem tells us that this will be the convolution of the initial data f (x) = F −1 f ] with the inverse Fourier transform of the Gaussian. On the third problem sheet you've already shown that, for a Gaussian in one variable F[e −a 2 x 2 ] = √ $\pi$},
author = {Skinner, David},
file = {:Users/eyob/Downloads/dbf-2023/GF/GreensPDE.pdf:pdf},
mendeley-groups = {Pinn},
pages = {126--142},
title = {{Green's functions for PDEs}},
url = {http://www.damtp.cam.ac.uk/user/dbs26/1BMethods/GreensPDE.pdf}
}
@article{TANG2022186,
abstract = {Solving linear system of equations stemming from Laplacian operators is at the heart of a wide range of applications. Due to the sparsity of the linear systems, iterative solvers such as Conjugate Gradient and Multigrid are usually employed when the solution has a large number of degrees of freedom. These iterative solvers can be seen as sparse approximations of the Green's function for the Laplacian operator. In this paper we propose a machine learning approach that regresses a Green's function from boundary conditions. This is enabled by a Green's function that can be effectively represented in a multi-scale fashion, drastically reducing the cost associated with a dense matrix representation. Additionally, since the Green's function is solely dependent on boundary conditions, training the proposed neural network does not require sampling the right-hand side of the linear system. We show results that our method outperforms state of the art Conjugate Gradient and Multigrid methods.},
author = {Tang, Jingwei and Azevedo, Vinicius C and Cordonnier, Guillaume and Solenthaler, Barbara},
doi = {https://doi.org/10.1016/j.cag.2022.07.016},
issn = {0097-8493},
journal = {Computers & Graphics},
keywords = { Green's function, Modeling and simulation, Poisson equation,Machine learning},
pages = {186--196},
title = {{Neural Green's function for Laplacian systems}},
url = {https://www.sciencedirect.com/science/article/pii/S0097849322001406},
volume = {107},
year = {2022}
}
@article{conradB,
   abstract = {Liouville proved that certain integrals, most famously e −x 2 dx, cannot be expressed in elementary terms. We explain how to give precise meaning to the notion of integration "in elementary terms", and we formulate Liouville's theorem that characterizes the possible form of elementary an-tiderivatives. Using this theorem, we deduce a practical criterion for proving such impossibility results in special cases. This criterion is illustrated for the Gaussian integral e −x 2 dx from probability theory, the logarithmic integral dt/ log(t) from the study of primes, and elliptic integrals. Our exposition is aimed at students who are familiar with calculus and elementary abstract algebra (at the level of polynomial rings F [t] over a field F).},
   author = {Brian Conrad},
   journal = {University of Michigan},
   title = {Impossibility theorems for elementary integration},
   url = {https://www.claymath.org/library/academy/LectureNotes05/Conrad.pdf},
   year = {2005},
}
@article{Katsnelson2023,
abstract = {We demonstrate, both analytically and numerically, that learning dynamics of neural networks is generically attracted towards a scale-invariant state. The effect can be modeled with quartic interactions between non-trainable variables (e.g. states of neurons) and trainable variables (e.g. weight matrix). Non-trainable variables are rapidly driven towards stochastic equilibrium and trainable variables are slowly driven towards learning equilibrium described by a scale-invariant distribution on a wide range of scales.},
author = {Katsnelson, M. I. and Vanchurin, V. and Westerhout, T.},
doi = {10.1016/j.physa.2022.128401},
file = {:Users/eyob/Documents/Master/University and College/Armour College of Engineering - Aerospace Engineering/2023 Spring/MMAE-500-01 Data Driven Modeling/Emergent-scale-invariance-in-neu_2023_Physica-A--Statistical-Mechanics-and-i.pdf:pdf},
issn = {03784371},
journal = {Physica A: Statistical Mechanics and its Applications},
keywords = {Deep learning,Neural networks,Saddle-point approximation,Scale invariance,Statistical physics,Theory of learning},
mendeley-groups = {Pinn},
pages = {128401},
publisher = {Elsevier B.V.},
title = {{Emergent scale invariance in neural networks}},
url = {https://doi.org/10.1016/j.physa.2022.128401},
volume = {610},
year = {2023}
}
@book{Nair2011,
abstract = {Advanced Topics in Applied Mathematics covers four essential applied mathematics topics: Green's functions, integral equations, Fourier transforms, and Laplace transforms. Also included is auseful discussion of topics such as the Wiener-Hopf method, finite Hilbert transforms, Cagniard–De Hoop method, and the proper orthog- onal decomposition. This book reflects Sudhakar Nair's long classroom experience and includes numerous examples of differential and integral equations from engineering and physics to illustrate the solution proce- dures. The text includes exercise sets at the end of each chapter and a solutions manual, which is available for instructors. SudhakarNair is the Associate Dean for AcademicAffairs of the Graduate College, Professor of Mechanical Engineering and Aerospace Engineer- ing, and Professor of Applied Mathematics at the Illinois Institute of Technology in Chicago. He is a Fellow of the ASME, an Associate Fellow of the AIAA, and a member of the American Academy of Mechanics as well as Tau Beta Pi and Sigma Xi. Professor Nair is the author ofnumerous research articles and Introduction to Continuum Mechanics (2009).},
author = {Nair, Sudhakar},
file = {:Users/eyob/Documents/Master/University and College/Armour College of Engineering - Aerospace Engineering/2023 Spring/MMAE-502-01 Engineering Analysis II/Sudhakar Nair - Advanced Topics in Applied Mathematics_ For Engineering and the Physical Sciences-Cambridge University Press (2011).pdf:pdf},
isbn = {9788527729833},
mendeley-groups = {Pinn},
publisher = {Cambridge University Press},
title = {{Advanced Topics in Applied Mathematics This}},
url = {www.cambridge.org/9781107006201},
year = {2011}
}
@article{Srivastava2018,
abstract = {Summary We show that deep convolutional neural networks (CNNs) can massively outperform traditional densely connected neural networks (NNs) (both deep or shallow) in predicting eigenvalue problems in mechanics. In this sense, we strike out in a new direction in mechanics computations with strongly predictive NNs whose success depends not only on architectures being deep but also being fundamentally different from the widely used to date..},
author = {Finol, David and Lu, Yan and Mahadevan, Vijay and Srivastava, Ankit},
doi = {https://doi.org/10.1002/nme.6012},
journal = {International Journal for Numerical Methods in Engineering},
keywords = {Phononic crystal,convolutional neural networks,deep learning in mechanics},
number = {5},
pages = {258--275},
title = {{Deep convolutional neural networks for eigenvalue problems in mechanics}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nme.6012},
volume = {118},
year = {2019}
}